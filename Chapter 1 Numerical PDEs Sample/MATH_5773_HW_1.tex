
\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\title{Homework 1-Math 5733}
\author{Evan Shapiro \\ Master's of Integrated Science, University of Colorado Denver}
\begin{document}
\title{Homework 1-Math 5733}
\author{Evan Shapiro \\ Master's of Integrated Science, University of Colorado Denver}
\maketitle
1.4\\
We start with the the following Cauchy differential equation:
\[ v'(t)= - (\alpha + \epsilon)v(t) \]
\[ v(0) = v_{0}, \]
where \(\alpha > 0\) is a measured parameter of the differential equation, and \(\epsilon\) is a perturbation in the measurement.\\
a) For a solution at time t = 1, so small perturbations in \(\alpha\) imply small changes in the solution, u(t)? In other words, is the solution at time t=1 stable for small perturbations in \(\alpha\)?\\
First, we solve the Cauchy problem:
\[ \frac{dv}{dt} = -(\alpha + \epsilon)v(t)\]

\[ \frac{dv}{v} = -(\alpha + \epsilon)dt\]
\[ ln(v) = -(\alpha + \epsilon)t+C \]
\[v(t)=e^{-(\alpha +\epsilon)t+C} \]
\[v(t) = v_{0}e^{-(\alpha+\epsilon)t}\]\\
Expand this function with a Taylor series around the parameter value \(\alpha\) for small values of \(\epsilon\), at time t = 1.
\[v(-(\alpha+\epsilon)) = u_{0}( e^{-\alpha} - \epsilon*e^{-c} ) \]\\,
where \(\epsilon*e^{-c}\) is this error term, and \(c \in(0,1)\), such that it maximizes the error term.
Please see the attached graph for reference.\\
We can use this Taylor expansion to bound the error of the function 
\[ e^{-(\alpha + \epsilon)t}\]
about the point \(t=1\). If we define the error to be bounded by some value \(\eta\), the difference between the exact and perturbed solution is:
\[|  e^{-(\alpha )t}-e^{-(\alpha + \epsilon)t}| \le |\epsilon*e^{-c}|, \]
which is of order \(\epsilon\), and is thus finitely bounded, the limit that $ \epsilon \to 0$ we retrieve the unperturbed solution. This means that a perturbation in the parameter $\alpha$ of order of \( \epsilon\) lead to perturbations in the data of order $\epsilon$, which makes this a stable system. 
\\
b) Next we assume that both \(u_{0}\) and $\alpha$ are measured. Discuss the stability of the problem in this context.
The solution for the Cauchy problem with both perturbed $\alpha$ and $\epsilon$  is:
\[v(t) = (u_{0}+\epsilon_{0})e^{-(\alpha+\epsilon_{1})t}. \]
This has a linear dependence on $u_{0}$ and an exponential dependence on $\alpha$, so it is stable with respect to small perturbations of $u_{0}$, regardless of the size of $u_{0}$, and is stable with respect to small perturbation of $\alpha$\\
1.5\\
Find the exact solutions for the following Cauchy problems:\\
(a) \[ u_{t} + 2xu_{x}=0\qquad  {x \in \mathbb{R},t>0} \] 		
\[ u(x,0) = e^{-x^{2}}. \]
\[ \frac{dx}{dt} = 2x \]
\[\frac{dx}{x} = 2dt\]
\[ ln(x) = 2t +C\]
\[ x = x_{0}e^{2t}\]
\[x_{0} = \frac{x}{e^{2t}} \]
\[u(x_{0},0) = e^{-\frac{x^2}{e^{4t}}}\]

(b) \[u_{t} - xu_{x} = 0 \qquad {x \in \mathbb{R}}, t>0 \]
\[u(x,0) = sin(87x) \]
\[ \frac{dx}{dt} = x \]
\[\frac{dx}{x} = dt\]
\[ ln(x) = t +C\]
\[ x = x_{0}e^{t}\]
\[x_{0} = xe^{-t} \]
\[u(x_{0},0) = sin(87xe^{-t})\]
(c) \[u_{t} + xu_{x} = x\qquad {x \in \mathbb{R}, t>0}\]
\[u(x,0) = cos(90x).\]
This is an inhomogeneous Cauchy ODE. So first we solve for homogeneous component, a(x,t), and then solve the inhomogeneous component. In the previous problem, part (b), we saw that this type of inital condition yields the solution.
\[u_{h} =cos(90xe^{-t})\qquad x_{0} = xe^{-t} \]
The solution to the characteristic equation is:
\[u_{c} = \int_{0}^t x_{0}e^{\tau}d\tau\]
\[ u_{c} = x_{0}(e^t-1)\]
Substituting in $x_{0}$:
\[u_{c} = x(1 -e^{-t})\]
The general solution is thus:
\[u(x,t)=cos(90xe^{-t}) +x(1-e^{-t})\]
Checking that this is the solution:\\
\[ u_{t} = 90xe^{-t}sin(90xe^{-t}) + e^{-t}\]
\[ xu_{x} = -90xe^{-t}sin(90xe^{-t}) + x(1-e^{-t})\]
\[u_{t} + xu_{x} = x\]
Thus, the solution is verified.\\
(d) \[u_{t} +xu_{x}  = x^2\qquad {x \in \mathbb{R}, t>0}\] 
\[u(x,0) = sin(87x)cos(90x)\]
\[u_{h} = sin(87xe^{-t})cos(90xe^{-t}),\qquad x_{0} = xe^{-t}\]
\[u_{c} = \int_{0}^t x_{0}^2e^{2t}\]
\[u_{c}=x_{0}^2(e^{2t}-1) \]
Substituting in $x_{0} = xe^{-t}$:
\[u_{c} = x^2(1-e^{-2t}\]
\[u(x,t) = sin(87xe^{-t})cos(90xe^{-t})+ x^2(1-e^{-2t})\]

1.7\\
Consider the two following Cauchy problems:
\[u_{t} + au_{x} =b(x,t),\qquad {x\in \mathbb{R}, t>0}\]
\[u(x,0) = \phi(x),\]
and
\[v_{t} + av_{x} =b(x,t),\qquad {x\in \mathbb{R}, t>0}\]
\[v(x,0) = \phi(x) +\epsilon(x).\]
$a$ is a constant, $b(x,t)$ and $\phi(x) $ and $\epsilon(x)$ are smooth functions.\\
Show that:
\[\sup_{x \in \mathbb{R}, t>0} |u(x,t)-v(x,t)|=|\sup_{x \in \mathbb{R}, t>0}\epsilon(x)|\]
 We can rewrite our initial conditions as:\\
\[u(x,0) = \phi(x_{0}),\]
\[v(x,0) = \phi(x_{0}) +\epsilon(x_{0}).\]
So we are solving:\\ 
\[\sup_{x \in \mathbb{R}, t>0} |u(x,t)-v(x,t)|=|\sup_{x \in \mathbb{R}, t>0}\epsilon(x_{0})|\]
Use method of characteristics to solve for $x_{0}$.\\
First solve u(x,t):\\
\[ \frac{dx}{dt} = a\]
\[ x = at + x_{0};\qquad x_{0} = x-at\]
Plug x back into the general solution for u(x,t):\\
\[u(x,t) = \phi(x_{0} -at) +  \int_{0}^{t} b(x,t)\]
Plug x into the general solution for v(x,t):\\
\[v(x,t) = \phi(x-at) + \epsilon(x-at) + \int_{0}^{t} b(x,t)\]
\[ v(x,t) - u(x,t) = \epsilon(x-at)\] 
\[ |v(x,t) - u(x,t)| = |\epsilon(x-at)|\] 
\[\sup_{x \in \mathbb{R}, t>0} |u(x,t)-v(x,t)|=\sup_{x \in \mathbb{R}, t>0}|\epsilon(x_{0})|\]\\
\\
1.10\\
\large Please see jupyter notebook.\\
\normalsize

\large 1.14\\
\normalsize
Consider the following Cauchy problem:\\
\[u_{tt} = c^2u_{xx}\]
\[u(x,0) = \phi(x)\]
\[u_{t}(x,0) = \psi(x)\]
Let:\\
\[v = u_{t} + cu_{x}.\]
Part (a)\\
Show that \\
\[v_{t} - cv_{x} = 0\]
Solution:\\
Given that $v = u_{t} + cu_{x}$,
\[v_{t} = u_{tt} + cu_{xt},\qquad v_{x} = u_{tx} + cu_{xx}.\]
This problem has $ u_{tt} = c^2u_{xx}$. Regarding the cross terms, according to Clairut if a function $u$ is defined on an open set $D \in \mathbb{R}^2 $, and both $u_{xy}, u_{yx}$ are continuous throught $D$, then $ u_{xy} = u_{yx}$. Thus
\[ v_{t} - cv_{x} = c^2u_{xx}+cu_{xt} - cu_{xt} - c^2u_{xx} =0\]

Part (b):\\
 Find v(x,t) expressed by $\phi$ and $\psi$.\\
Solution:\\
First recognize that:\\
\[ \frac{\partial v(x,t) }{\partial t} = v_{t} - cv_{x},\]
which motivates us to use the method of characteristics to solve for v(x,t)  :\\
\[ v_{t} - cv_{x}=0\]
\[ \frac{dx}{dt} = -c\]
\[ x = x_{0} -ct\]
\[x_{0} = x + ct\]
\[ v(x,0) = v(x_{0},0) = v(x,t)= u_{t}(x,0) + cu_{x}(x,0)\]
\[ v(x,t) = c\phi ' (x+ct) + \psi(x+ct) \]
Part (c)\\
Explain why
\[ u(x,t) = \phi(x-ct) + \int_{0}^{t} v[x-c(t-\tau),\tau]d\tau\]
\\
Solution:\\
Use the solution for $x_{0}$ from the method of characteristics to solve the inhomogeneous component of this problem.
\[\frac{dx}{dt} = c\]
\[ x = x_{0} +ct\]
\[ x_{0} = x-ct\]
\[u(x,0)= u(x,t) = \phi(x-ct) + \int_{0}^{t}v(x_{0}+c\tau, \tau) d\tau\]
Substituting $ x_{0}$ into the integral\\
\[u(x,t) = \phi(x-ct) + \int_{0}^{t}v(x - ct + c\tau,\tau)d\tau\]
\[u(x,t) = \phi(x-ct) + \int_{0}^{t}v(x-c(t-\tau),\tau)  d\tau\]
Part (d)\\
Derive the expression\\
\[ u(x,t) = \frac{1}{2}(\phi(x+ct) \pm \phi(x-ct)) +\frac{1}{2c}\int_{x-ct}^{x+ct}\psi(\theta)d\theta\]
Solution:\\
Substitute the solution from part b
\[ v(x,t) = c\phi ' (x+ct) + \psi(x+ct) \]
into the solution for part c\\
\[u(x,t) = \phi(x-ct) + \int_{0}^{t}v(x-c(t-\tau),\tau)  d\tau.\]
This becomes:
\[ u(x,t) = \phi(x-ct) + \int_{0}^{t}c\phi'(x-c(t-\tau) +c\tau)d\tau + \int_{0}^{t}\psi(x-c(t-\tau)+\tau)d\tau,\]
which simplifies to
\[ u(x,t) = \phi(x-ct) + \int_{0}^{t}c\phi'(x-ct +2c\tau)d\tau + \int_{0}^{t}\psi(x-ct+2c\tau)d\tau.\]
Lets solve the first integral
\[\int_{0}^{t}c\phi'(x-ct +2c\tau)d\tau\]
by subsituting in
\[ u(\tau) = x -ct + 2c\tau, \qquad du(\tau) = 2cd\tau. \]
The new limits of integration are:
\[u(0) = x - ct, \qquad u(t) = x + ct\]
The new integral is:
\[\frac{1}{2}\int_{x-ct}^{x+ct}\phi'(u)du\]
In part b we took the derivative of $\phi$ with respect to x to yield $\phi'$. Using calculus we see
\[\frac{d\phi}{dx} = \frac{du}{dx}\frac{d\phi}{du}\]
with
\[\frac{du}{dx} = 1\]
So the integral becomes:
\[\frac{1}{2}\int_{x-ct}^{x+ct}d\phi(u),\]
which according to the Fundamental Theorem of Calculus yields
\[ \int_{0}^{t}c\phi'(x-ct +2c\tau)d\tau = \frac{1}{2}(\phi(x+ct)-\phi(x-ct)).\]
Using the same u-subsitution in the second integral as we did for the first yields the following solution for u(x,t):
\[ \int_{0}^{t}\psi(x-ct+2c\tau)d\tau= \frac{1}{2c}\int_{x-ct}^{x+ct}\psi(u)du\]
	\\
\large $1.15$ Theoretical analysis of error as a function of step-size\\
\normalsize
(a) Let $0\le(m+1) \le T$ and let u(t) be the solution of 1.18. Show that if $t_{m} = m \Delta t$, then
\[\frac{u(t_{m+1}) - u(t_{m})}{\Delta} = u(t_{m}) +\tau_{m}\]
where the truncation error $\tau_{m}$ is satisfies
\[ |\tau_{m}| \le \frac{\Delta t}{2}e^T\qquad for\quad 0\le(m+1)\le T\]
Use a Taylor exapnasion on $u(t_{m+1})$ to derive the truncation error. \\
\[u(t_{m+1}) = u(t_{m} +\Delta t) = u(t_{m}) + u'(t_{m})\Delta t + \frac{u''(c)}{2}\Delta t^2,\] 
 where c is a number between 0 and T.\\
We know apriori that $u(t) = e^T$, so evaluate the Taylor expansion with this solution
\[u(t_{m+1}) = u(t_{m} +\Delta t) = e^{t_{m}}+ e^{t_{m}}\Delta t +\frac{e^c}{2}\Delta t^2.\] 
Since $e^T$ is a monotonically increasing function,
\[\frac{e^c}{2}\Delta t^2 = \tau_{m} \le \frac{e^T}{2}\Delta t^2 .\]
Substituting this all back into original expression for the derivative
\[\frac{u(t_{m+1}) - u(t_{m})}{\Delta} = \frac{e^{t_{m}}+ e^{t_{m}}\Delta t +\frac{e^c}{2}\Delta t^2 -{e^{t_{m}}}}{\Delta t}=e^{t_{m}} + \frac{e^c}{2}\Delta t\]
\[\frac{u(t_{m+1}) - u(t_{m})}{\Delta} =  u(t_{m}) +\tau_{m}\]
(b)  Assume the ${v_{m}}$ is the corresponding forward Euler solution given by
\[v_{m+1} = (1+\Delta t)v_{m},\qquad v_{0} = 1,\]
and let $w_{m} = u_{m}-v_{m}$ be the error at time $t_{m} = m\Delta t.$ Explain why ${w_{m}}$ satisfies the difference equation
\[ w_{m+1} = (1+\Delta t)w_{m} + \Delta t \tau_{m}, \qquad w_{0} = 0.\]
From the definition for the derivative
\[ u(t_{m+1}) = (u(t_{m}) + \tau_{m})\Delta t + u(t_{m})\]
\[ u(t_{m+1})  = u(t_{m})(\Delta t +1) + \tau \Delta t\]
\[w_{m+1} = u_{m+1} - v_{m+1} = u(t_{m})(\Delta t +1) + \tau \Delta t-(1+\Delta t)v_{m}\]
\[w_{m+1} = u_{m+1} - v_{m+1} = w(t_{m})(\Delta t +1) + \tau \Delta t\]
(c) Use induction on m to prove that
\[ |wm| \le \frac{\Delta t}{2}e^T(e^{t_{m}}-1)\qquad for\quad 0\le t_{m} \le T.\]
Evaluate the first few terms of the partial sum\\
$$
w_{0} = 0\\
$$
$$
w_{1} = \Delta t \tau,\\
$$
$$
w_{2} = (1+ \Delta t)\Delta t \tau_{1} +\Delta t \tau_{2}\\
$$
$$
w_{2} \le \Delta t^2\tau_{2} +2\Delta t \tau_{2}\qquad as\quad \tau_{1} \le \tau_{2}\\
$$
$$
w_{3} = (1+\Delta t)(\Delta t^2 \tau_{2} +2\Delta t \tau_{2}) +\Delta t \tau{3} ) +\Delta t \tau_{3}\\
$$
$$
w_{3} \le \Delta t^3 \tau_{3} + 3\Delta t^2\tau_{3} +3\Delta t \tau_{3}\\
$$
$$
w_{m} = \tau_{m}\sum_{i=1}^{m} {m \choose i} \Delta t^i\\
$$
These coefficients seem to follow the format of the binomial series, but not exactly. Lets use induction to proves this series follows this behavior. Assume this is true for $w_{m},$ and show that it holds for $w_{m+1}$.
$$
w_{m+1} =\tau_{m+1} \sum_{i=1}^{m+1}{m+1 \choose i} \Delta t^i
$$
Evaluate the last term in the series, to create a series similar to that of $w_{m}$
$$
w_{m+1} = \sum_{i=1}^{m}{m+1 \choose i} \Delta t^i +\tau_{m+1}\Delta t^{m+1}
$$
In the limit that $m+1 \to \infty, \Delta t^{m+1} \to 0$, so we can drop the last term in the above equation.
Use a choose identity to simplify the choose function:
\[ {m \choose i} = {m -1 \choose i} + {m-1 \choose i-1}\]
\[ {m+1 \choose i } = {m \choose i} + { m \choose i-1}\]
Substitute this into our sum:
$$
w_{m+1} =\tau_{m+1}( \sum_{i=1}^{m} {m \choose i}\Delta\ t^i +\sum_{i=1}^{m} { m \choose i-1}\Delta\ t^i)
$$
Subsituting $j = i-1$ into the second term in the above equation yields
\[w_{m+1} =\tau_{m+1}( \sum_{i=1}^{m} {m \choose i}\Delta\ t^i +\sum_{j=0}^{m} { m \choose j}\Delta\ t^{j+1})\]
\[w_{m+1} =\tau_{m+1}( \sum_{i=1}^{m} {m \choose i}\Delta\ t^i +\sum_{j=1}^{m} { m \choose j}\Delta\ t^{j+1} +\Delta t)\]
\[w_{m+1} =\tau_{m+1}( \sum_{i=1}^{m} {m \choose i}\Delta\ t^i +\Delta t\sum_{j=1}^{m} { m \choose j}\Delta\ t^{j} +\Delta t)\]
 \[w_{m+1} = \tau_{m+1}\sum_{i=1}^{m} {m \choose i}\Delta\ t^i (1+\Delta t) + \Delta t \tau_{m+1}\]
which almost satisfies our original condition.
Now having almost proven that $w_{m} =\tau_{m}\sum_{i=1}^{m} {m \choose i} \Delta t^i$, show that this satisfies the original bound.
\[ \tau_{m}\sum_{i=1}^{m} {m \choose i} \Delta t^i =\tau_{m}(\sum_{i=0}^{m} {m \choose i} \Delta t^i -1)\]
By the binomial theorem this tields
\[\tau_{m}(\sum_{i=0}^{m} {m \choose i} \Delta t^i -1) = \tau_{m}(1+\Delta t)^m -1\]
Well $\Delta tm = t_{m}$ so $ \Delta t = \frac{t_{m}}{m}$
\[ \lim_{ m \to \infty}\tau_{m}(1+ \frac{t_{m}}{m})^m -1 = e^{t_{m}}-1]\]
which satisfies our original bound,
\[ |wm| \le \frac{\Delta t}{2}e^T(e^{t_{m}}-1)\qquad for\quad 0\le t_{m} \le T.\]
\normalsize





\end{document}